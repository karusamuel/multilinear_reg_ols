{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multilinear regression, also called multiple linear regression, is a statistical technique used to model the relationship between one dependent (response) variable and two or more independent (predictor) variables. \n",
    "\n",
    "The goal of multiple linear regression is to understand how the independent variables influence the dependent variable.\n",
    "\n",
    "\n",
    "1. Basic Formula of Multilinear Regression\n",
    "\n",
    "In multiple linear regression, the relationship between the dependent variable y and the independent variables x1,x2,...,xp​ is given by:\n",
    "\n",
    "    y=β0+β1x1+β2x2+...+βpxp+ϵ\n",
    "\n",
    "Where:\n",
    "\n",
    "    y= Dependent variable (the outcome or predicted value).\n",
    "    x1,x2,...,xp= Independent variables (predictors).\n",
    "    β0= Intercept (the value of yy when all xx variables are 0).\n",
    "    β1,β2,...,βp​ = Coefficients of the independent variables (how much each xixi​ contributes to the outcome).\n",
    "    ϵϵ = Error term (residuals), representing the difference between the predicted value and the actual value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 716,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports \n",
    "\n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "import numpy as np \n",
    "import  statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 717,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displacement</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>weight</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>model year</th>\n",
       "      <th>origin</th>\n",
       "      <th>car name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>307.0</td>\n",
       "      <td>130</td>\n",
       "      <td>3504</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>chevrolet chevelle malibu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>350.0</td>\n",
       "      <td>165</td>\n",
       "      <td>3693</td>\n",
       "      <td>11.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>buick skylark 320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>318.0</td>\n",
       "      <td>150</td>\n",
       "      <td>3436</td>\n",
       "      <td>11.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>plymouth satellite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>8</td>\n",
       "      <td>304.0</td>\n",
       "      <td>150</td>\n",
       "      <td>3433</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>amc rebel sst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>8</td>\n",
       "      <td>302.0</td>\n",
       "      <td>140</td>\n",
       "      <td>3449</td>\n",
       "      <td>10.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>ford torino</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mpg  cylinders  displacement  horsepower  weight  acceleration  \\\n",
       "0  18.0          8         307.0         130    3504          12.0   \n",
       "1  15.0          8         350.0         165    3693          11.5   \n",
       "2  18.0          8         318.0         150    3436          11.0   \n",
       "3  16.0          8         304.0         150    3433          12.0   \n",
       "4  17.0          8         302.0         140    3449          10.5   \n",
       "\n",
       "   model year  origin                   car name  \n",
       "0          70       1  chevrolet chevelle malibu  \n",
       "1          70       1          buick skylark 320  \n",
       "2          70       1         plymouth satellite  \n",
       "3          70       1              amc rebel sst  \n",
       "4          70       1                ford torino  "
      ]
     },
     "execution_count": 717,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./data/auto-mpg.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ". inspect "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 718,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mpg             float64\n",
       "cylinders         int64\n",
       "displacement    float64\n",
       "horsepower        int64\n",
       "weight            int64\n",
       "acceleration    float64\n",
       "model year        int64\n",
       "origin            int64\n",
       "car name         object\n",
       "dtype: object"
      ]
     },
     "execution_count": 718,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining our variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 719,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_base,x_multi,y\n",
    "\n",
    "x_base = df[[\"weight\"]]\n",
    "x_multi = df[[\"displacement\",\"weight\",\"horsepower\",\"acceleration\"]]\n",
    "y = df['mpg']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## simple linear regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 720,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>mpg</td>       <th>  R-squared:         </th> <td>   0.693</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.692</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   878.8</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 21 Nov 2024</td> <th>  Prob (F-statistic):</th> <td>6.02e-102</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>19:56:42</td>     <th>  Log-Likelihood:    </th> <td> -1130.0</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   392</td>      <th>  AIC:               </th> <td>   2264.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   390</td>      <th>  BIC:               </th> <td>   2272.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "     <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>  <td>   46.2165</td> <td>    0.799</td> <td>   57.867</td> <td> 0.000</td> <td>   44.646</td> <td>   47.787</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>weight</th> <td>   -0.0076</td> <td>    0.000</td> <td>  -29.645</td> <td> 0.000</td> <td>   -0.008</td> <td>   -0.007</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>41.682</td> <th>  Durbin-Watson:     </th> <td>   0.808</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  60.039</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.727</td> <th>  Prob(JB):          </th> <td>9.18e-14</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 4.251</td> <th>  Cond. No.          </th> <td>1.13e+04</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.13e+04. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &       mpg        & \\textbf{  R-squared:         } &     0.693   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.692   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     878.8   \\\\\n",
       "\\textbf{Date:}             & Thu, 21 Nov 2024 & \\textbf{  Prob (F-statistic):} & 6.02e-102   \\\\\n",
       "\\textbf{Time:}             &     19:56:42     & \\textbf{  Log-Likelihood:    } &   -1130.0   \\\\\n",
       "\\textbf{No. Observations:} &         392      & \\textbf{  AIC:               } &     2264.   \\\\\n",
       "\\textbf{Df Residuals:}     &         390      & \\textbf{  BIC:               } &     2272.   \\\\\n",
       "\\textbf{Df Model:}         &           1      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{const}  &      46.2165  &        0.799     &    57.867  &         0.000        &       44.646    &       47.787     \\\\\n",
       "\\textbf{weight} &      -0.0076  &        0.000     &   -29.645  &         0.000        &       -0.008    &       -0.007     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 41.682 & \\textbf{  Durbin-Watson:     } &    0.808  \\\\\n",
       "\\textbf{Prob(Omnibus):} &  0.000 & \\textbf{  Jarque-Bera (JB):  } &   60.039  \\\\\n",
       "\\textbf{Skew:}          &  0.727 & \\textbf{  Prob(JB):          } & 9.18e-14  \\\\\n",
       "\\textbf{Kurtosis:}      &  4.251 & \\textbf{  Cond. No.          } & 1.13e+04  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [2] The condition number is large, 1.13e+04. This might indicate that there are \\newline\n",
       " strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                    mpg   R-squared:                       0.693\n",
       "Model:                            OLS   Adj. R-squared:                  0.692\n",
       "Method:                 Least Squares   F-statistic:                     878.8\n",
       "Date:                Thu, 21 Nov 2024   Prob (F-statistic):          6.02e-102\n",
       "Time:                        19:56:42   Log-Likelihood:                -1130.0\n",
       "No. Observations:                 392   AIC:                             2264.\n",
       "Df Residuals:                     390   BIC:                             2272.\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const         46.2165      0.799     57.867      0.000      44.646      47.787\n",
       "weight        -0.0076      0.000    -29.645      0.000      -0.008      -0.007\n",
       "==============================================================================\n",
       "Omnibus:                       41.682   Durbin-Watson:                   0.808\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               60.039\n",
       "Skew:                           0.727   Prob(JB):                     9.18e-14\n",
       "Kurtosis:                       4.251   Cond. No.                     1.13e+04\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.13e+04. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 720,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# simple linear regresion in statsmodel\n",
    "model = sm.OLS(y,sm.add_constant(x_base))\n",
    "ols_results = model.fit()\n",
    "ols_results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 721,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  to compare stsmodels and scikit learn results \n",
    "\n",
    "def print_results(sk_model,ols_model):\n",
    "    sklearn_baseline_model\n",
    "    print(f\"\"\"\n",
    "\n",
    "\n",
    "StatsModels intercept:    {ols_model.params[\"const\"]}\n",
    "scikit-learn intercept:   {sk_model.intercept_}\n",
    "\n",
    "StatsModels coefficient:\\n{ols_model.params}\n",
    "scikit-learn coefficient: {sk_model.coef_}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## in sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 722,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple model in sklearn\n",
    "sklearn_baseline_model = LinearRegression()\n",
    "sk_results =  sklearn_baseline_model.fit(y=y,X=x_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 723,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "StatsModels intercept:    46.216524549017606\n",
      "scikit-learn intercept:   46.21652454901758\n",
      "\n",
      "StatsModels coefficient:\n",
      "const     46.216525\n",
      "weight    -0.007647\n",
      "dtype: float64\n",
      "scikit-learn coefficient: [-0.00764734]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print_results(sk_model=sk_results,ols_model=ols_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multilinear Regression\n",
    "\n",
    "linear regression with multiple variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 724,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>mpg</td>       <th>  R-squared:         </th> <td>   0.707</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.704</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   233.4</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 21 Nov 2024</td> <th>  Prob (F-statistic):</th> <td>9.63e-102</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>19:56:42</td>     <th>  Log-Likelihood:    </th> <td> -1120.6</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   392</td>      <th>  AIC:               </th> <td>   2251.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   387</td>      <th>  BIC:               </th> <td>   2271.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     4</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td></td>          <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>        <td>   45.2511</td> <td>    2.456</td> <td>   18.424</td> <td> 0.000</td> <td>   40.422</td> <td>   50.080</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>displacement</th> <td>   -0.0060</td> <td>    0.007</td> <td>   -0.894</td> <td> 0.372</td> <td>   -0.019</td> <td>    0.007</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>weight</th>       <td>   -0.0053</td> <td>    0.001</td> <td>   -6.512</td> <td> 0.000</td> <td>   -0.007</td> <td>   -0.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>horsepower</th>   <td>   -0.0436</td> <td>    0.017</td> <td>   -2.631</td> <td> 0.009</td> <td>   -0.076</td> <td>   -0.011</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>acceleration</th> <td>   -0.0231</td> <td>    0.126</td> <td>   -0.184</td> <td> 0.854</td> <td>   -0.270</td> <td>    0.224</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>38.359</td> <th>  Durbin-Watson:     </th> <td>   0.861</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  51.333</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.715</td> <th>  Prob(JB):          </th> <td>7.13e-12</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 4.049</td> <th>  Cond. No.          </th> <td>3.56e+04</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 3.56e+04. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &       mpg        & \\textbf{  R-squared:         } &     0.707   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.704   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     233.4   \\\\\n",
       "\\textbf{Date:}             & Thu, 21 Nov 2024 & \\textbf{  Prob (F-statistic):} & 9.63e-102   \\\\\n",
       "\\textbf{Time:}             &     19:56:42     & \\textbf{  Log-Likelihood:    } &   -1120.6   \\\\\n",
       "\\textbf{No. Observations:} &         392      & \\textbf{  AIC:               } &     2251.   \\\\\n",
       "\\textbf{Df Residuals:}     &         387      & \\textbf{  BIC:               } &     2271.   \\\\\n",
       "\\textbf{Df Model:}         &           4      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                      & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{const}        &      45.2511  &        2.456     &    18.424  &         0.000        &       40.422    &       50.080     \\\\\n",
       "\\textbf{displacement} &      -0.0060  &        0.007     &    -0.894  &         0.372        &       -0.019    &        0.007     \\\\\n",
       "\\textbf{weight}       &      -0.0053  &        0.001     &    -6.512  &         0.000        &       -0.007    &       -0.004     \\\\\n",
       "\\textbf{horsepower}   &      -0.0436  &        0.017     &    -2.631  &         0.009        &       -0.076    &       -0.011     \\\\\n",
       "\\textbf{acceleration} &      -0.0231  &        0.126     &    -0.184  &         0.854        &       -0.270    &        0.224     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 38.359 & \\textbf{  Durbin-Watson:     } &    0.861  \\\\\n",
       "\\textbf{Prob(Omnibus):} &  0.000 & \\textbf{  Jarque-Bera (JB):  } &   51.333  \\\\\n",
       "\\textbf{Skew:}          &  0.715 & \\textbf{  Prob(JB):          } & 7.13e-12  \\\\\n",
       "\\textbf{Kurtosis:}      &  4.049 & \\textbf{  Cond. No.          } & 3.56e+04  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [2] The condition number is large, 3.56e+04. This might indicate that there are \\newline\n",
       " strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                    mpg   R-squared:                       0.707\n",
       "Model:                            OLS   Adj. R-squared:                  0.704\n",
       "Method:                 Least Squares   F-statistic:                     233.4\n",
       "Date:                Thu, 21 Nov 2024   Prob (F-statistic):          9.63e-102\n",
       "Time:                        19:56:42   Log-Likelihood:                -1120.6\n",
       "No. Observations:                 392   AIC:                             2251.\n",
       "Df Residuals:                     387   BIC:                             2271.\n",
       "Df Model:                           4                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "================================================================================\n",
       "                   coef    std err          t      P>|t|      [0.025      0.975]\n",
       "--------------------------------------------------------------------------------\n",
       "const           45.2511      2.456     18.424      0.000      40.422      50.080\n",
       "displacement    -0.0060      0.007     -0.894      0.372      -0.019       0.007\n",
       "weight          -0.0053      0.001     -6.512      0.000      -0.007      -0.004\n",
       "horsepower      -0.0436      0.017     -2.631      0.009      -0.076      -0.011\n",
       "acceleration    -0.0231      0.126     -0.184      0.854      -0.270       0.224\n",
       "==============================================================================\n",
       "Omnibus:                       38.359   Durbin-Watson:                   0.861\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               51.333\n",
       "Skew:                           0.715   Prob(JB):                     7.13e-12\n",
       "Kurtosis:                       4.049   Cond. No.                     3.56e+04\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 3.56e+04. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 724,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# multi model in ols \n",
    "\n",
    "ols_multi_model = sm.OLS(endog=y,exog=sm.add_constant(x_multi))\n",
    "ols_multi_results = ols_multi_model.fit()\n",
    "ols_multi_results.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## in sklearn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 725,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multi linear regression in sklearn \n",
    "sklearn_multi_model = LinearRegression()\n",
    "sklearn_multi_results = sklearn_multi_model.fit(X=x_multi,y=y)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 726,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "StatsModels intercept:    45.25113969933501\n",
      "scikit-learn intercept:   45.251139699334956\n",
      "\n",
      "StatsModels coefficient:\n",
      "const           45.251140\n",
      "displacement    -0.006001\n",
      "weight          -0.005281\n",
      "horsepower      -0.043608\n",
      "acceleration    -0.023148\n",
      "dtype: float64\n",
      "scikit-learn coefficient: [-0.00600087 -0.00528051 -0.04360773 -0.023148  ]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_results(sk_model=sklearn_multi_results,ols_model=ols_multi_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple Linear Regression Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot fit "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows the true (blue) vs. predicted (red) values, with the particular predictor along the x-axis\n",
    "\n",
    "Note that unlike with a simple regression, the red dots don't appear in a perfectly straight line.\n",
    "\n",
    "This is because their predictions are made based on the entire model, not just this predictor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 727,
   "metadata": {},
   "outputs": [],
   "source": [
    "#single column\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "multiple "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 728,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partial regression plots "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a partial regression plot shows the \"partial\" effect of one predictor, independent of the other predictors in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 729,
   "metadata": {},
   "outputs": [],
   "source": [
    "# single column \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 730,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multi column\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ploting Residuals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "component and component-plus-residual plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 731,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ccpr plot "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting all at Once "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plotting all four at once for a given predictior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 732,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all plot at once "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 733,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To do all columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple Regression Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiple regression models, like simple regression models, can be evaluated using R-Squared (coefficient of determination) for measuring the amount of explained variance, and the F-statistic for determining statistical significance. You also may want to consider using other metrics, including adjusted R-Squared and error-based metrics such as MAE and RMSE. Each metric provides slightly different information, so you will need additional information from stakeholders in order to choose the most appropriate one(s)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reviewing F-Statistic and R-Squared\n",
    "\n",
    "First, we can check the model's F-statistic and F-statistic p-value to see if the model was statistically significant overall:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 734,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limitations of R-Squared:\n",
    "\n",
    "R-Squared is a commonly used metric for model performance, but it has limitations. First, it always increases when more predictors are added to the model, which can lead to overfitting. This can result in unstable coefficients and a violation of linear regression assumptions. To address this, Adjusted R-Squared can be used, which accounts for the number of predictors.\n",
    "\n",
    "Second, R-Squared is sensitive to the variance in the data. Small variances in predictors can lead to a low R-Squared, while large variances can result in a high R-Squared, regardless of how well the model fits the true relationship. It can also be difficult to explain to non-technical stakeholders. To address this, error-based metrics (e.g., MSE, RMSE) can be used to evaluate model performance in terms of prediction errors rather than variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error-Based Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 735,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting  predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Error-based metrics are used to evaluate the performance of regression models by quantifying the difference between predicted and actual values. These metrics focus on the errors (or residuals) the model makes in its predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Absolute Error (MAE)\n",
    "\n",
    "**Mean Absolute Error (MAE)** is calculated as the average of the absolute differences between the predicted and actual values. It is given by the formula:\n",
    "\n",
    "\\[\n",
    "MAE = \\frac{1}{n} \\sum_{i=1}^{n} |y_i - \\hat{y_i}|\n",
    "\\]\n",
    "\n",
    "Where:\n",
    "- \\(y_i\\) is the actual value,\n",
    "- \\(\\hat{y_i}\\) is the predicted value,\n",
    "- \\(n\\) is the number of data points.\n",
    "\n",
    "### Key Points:\n",
    "- **Interpretability**: MAE is in the same units as the target variable, making it easy to interpret.\n",
    "- **Equal Weight to All Errors**: MAE treats all errors equally, meaning it does not penalize larger errors more heavily compared to smaller ones.\n",
    "- **Lower is Better**: A lower MAE indicates a model that makes smaller average errors in its predictions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 736,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAE calculated "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### in sklearn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 737,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAE sklearn\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Root Mean Squeared Error (RMSE)\n",
    "\n",
    "Root Mean Squared Error (RMSE) is a popular error metric used to measure the difference between the predicted values and the actual values in regression models. Unlike Mean Absolute Error (MAE), RMSE penalizes larger errors more heavily due to the squaring of the residuals. It provides a more sensitive measure of model performance, especially when large errors are particularly undesirable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#### **Formula for RMSE**:\n",
    "\n",
    "The RMSE is calculated using the following formula:\n",
    "\n",
    "\\[\n",
    "RMSE = \\sqrt{\\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y_i})^2}\n",
    "\\]\n",
    "\n",
    "Where:\n",
    "- \\( y_i \\) is the actual value,\n",
    "- \\( \\hat{y_i} \\) is the predicted value,\n",
    "- \\( n \\) is the number of data points.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 738,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RMSE calculated\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In sklearn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 739,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RMSE sklearn \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note:\n",
    "\n",
    "    Choose MAE if you want a simple, easy-to-interpret measure of average error that treats all errors equally.\n",
    "    Choose RMSE if you want to penalize larger errors more and have a metric that gives more weight to significant deviations from the actual values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
